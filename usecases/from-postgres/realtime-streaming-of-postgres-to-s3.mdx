---
title: "Real-time Streaming of Postgres to S3"
---

PeerDB can stream your PostgreSQL data to your S3 bucket in the form of `.avro` files. Please **fill in your AWS credentials** in [PeerDB's docker-compose file](https://github.com/PeerDB-io/peerdb/blob/e9fe3e03e242abc37a7526d7132c1f7232e00e5f/docker-compose.yml#L89-L91C36) before running it. 

### Step 1: CREATE Postgres and S3 Peers
    1. [CREATE Postgres PEER](https://docs.peerdb.io/sql/commands/create-peer#postgresql-peer)
    2. [CREATE S3 PEER](https://docs.peerdb.io/sql/commands/create-peer#s3-peer)

### Step 2: Create and populate tables on the Postgres PEER
    Below script helps creates and populate `pgbench_history` with dummy data on your PostgreSQL peer.
    ```sh
    curl -O https://peerdb-sample-data.s3.us-east-2.amazonaws.com/import_data_for_tutorial.sh
    chmod +x import_data_for_tutorial.sh
    # "postgres://user:password@hostname:5432/dbname" 
    # is the connection string of your PostgreSQL peer.
    ./import_data_for_tutorial.sh "postgres://user:password@hostname:5432/dbname"
    ```

### Step 3: Kick off MIRROR with 8 threads and batch size of 10 seconds
    
    ```sql
    CREATE MIRROR postgres_to_s3_tutorial
    FROM postgres_peer TO s3_peer FOR
    $$SELECT * FROM public.pgbench_history WHERE mtime BETWEEN {{.start}} AND {{.end}}$$
    WITH (
    	watermark_column = 'mtime',
    	watermark_table_name = 'pgbench_history',
    	mode = 'append',
    	parallelism = 8,
    	refresh_interval = 10,
    	batch_duration_timestamp = 10,
    	sync_data_format = 'avro',
    	destination_table_name = 'public.pgbench_history',
        num_rows_per_partition = 10
    );
    ```
    
### Step 4: Monitor the MIRROR
You can connect to ``localhost:8233`` to gain full visibility into the different jobs and steps that PeerDB performs under the hood to manage the MIRROR.

### Step 5: Validate the MIRROR
In 1-2 minutes the MIRROR should complete syncing data. Now validate the data on both postgres and S3 peers. The number of `.avro` files in the bucket should be equal to the number of partitions (total rows in your source table divided by `num_rows_per_partition`).
```sql
SELECT count(*) FROM postgres_peer.pgbench_history;
```

```shell
aws ls s3://<bucket>/<prefix>/ --recursive
```