
Below table shows supported data types across **PostgreSQL, BigQuery and Snowflake**.

#### Primitive Data Types

<br></br>

| Source | Destinations
| --- | --- |
| <b>PostgreSQL</b> | <b>PostgreSQL</b> | <b>BigQuery</b> | <b>Snowflake</b> | <b>Clickhouse</b> | <b>ElasticSearch</b> |
| `smallint` | `smallint` | `INTEGER` | `INTEGER` | `Int16` |
| `integer` | `integer` | `INTEGER` | `INTEGER` | `Int32` |
| `bigint` | `bigint` | `INTEGER` | `INTEGER` | `Int64` |
| `float4` | `float4` | `FLOAT` | `FLOAT` | `Float32` |
| `double precision` | `double precision` | `FLOAT` | `FLOAT` | `Float64` |
| `boolean` | `bool` | `BOOLEAN` | `BOOLEAN` | `Bool`
| `"char"` | `CHAR` | `STRING` | `STRING` | `FixedString(1)`
| `varchar` | `varchar` | `STRING` | `STRING` | `String`
| `date` | `date` | `DATE` | `DATE` | `Date`
| `json` | `json` | `STRING` | `VARIANT` | `String`
| `numeric` | `numeric` | `BIGNUMERIC` | `NUMBER` | `Decimal`
| `text` | `text` | `STRING` | `STRING` | `String`
| `timestamp` | `timestamp` | `TIMESTAMP` | `TIMESTAMP_NTZ` | `DateTime64(6)`
| `timestamp with time zone` | `timestamp with time zone` | `TIMESTAMP` | `TIMESTAMP_TZ` | `DateTime64(6)`
| `time` | `time` | `TIME` | `TIME` | `String`
| `bit` | `bit` | `BYTES` | `BINARY` | Coming soon!
| `bit varying` | `varbit` | `BYTES` | `BINARY` | Coming soon!
| `bytea` | `bytea` | `BYTES` | `BINARY` | Coming soon!
| `geography` | `geography` | `GEOGRAPHY` | `GEOGRAPHY` | Coming soon!
| `geometry` | `geometry` | `GEOGRAPHY` | `GEOMETRY` | Coming soon!
| `inet` | `inet` | `STRING` | `STRING` | Coming soon!
| `macaddr` | `macaddr` | `STRING` | `STRING` | Coming soon!
| `cidr` | `cidr` | `STRING` | `STRING` | Coming soon!
| `hstore` | `hstore` | `JSON` | `VARIANT` | Coming soon!
| `uuid` | `uuid` | `STRING` | `STRING` | `uuid`

<br></br>
#### Array Data Types
<br></br>
| Source | Destinations
| --- | --- |
| <b>PostgreSQL Type</b> | <b>PostgreSQL</b> | <b>BigQuery</b> | <b>Snowflake</b> | <b>Clickhouse</b> |
| `ARRAY<INT2>` | `ARRAY<INT2>` | `ARRAY<INT>` | `VARIANT` | `Array<Int16>` |
| `ARRAY<INT4>` | `ARRAY<INT4>` | `ARRAY<INT>` | `VARIANT` | `Array<Int32>` |
| `ARRAY<INT8>` | `ARRAY<INT8>` | `ARRAY<INT>` | `VARIANT` | `Array<Int64>` |
| `ARRAY<FLOAT4>` | `ARRAY<FLOAT4>` | `ARRAY<FLOAT>` | `VARIANT` | `Array<Float32>` |
| `ARRAY<DOUBLE PRECISION>` | `ARRAY<DOUBLE PRECISION>` | `ARRAY<DOUBLE PRECISION>` | `VARIANT` | `Array<Float64>` |
| `ARRAY<BOOL>` | `ARRAY<BOOL>` | `ARRAY<BOOL>` | `VARIANT` | `Array<Bool>` |
| `ARRAY<VARCHAR>` | `ARRAY<VARCHAR>` | `ARRAY<STRING>` | `VARIANT` | `Array<String>` |
| `ARRAY<TEXT>` | `ARRAY<TEXT>` | `ARRAY<STRING>` | `VARIANT` | `Array<String>` |
| `ARRAY<DATE>` | `ARRAY<DATE>` | `ARRAY<DATE>` | `VARIANT` | Coming soon! |
| `ARRAY<TIMESTAMP>` | `ARRAY<TIMESTAMP>` | `ARRAY<TIMESTAMP>` | `VARIANT` | Coming soon! |
| `ARRAY<TIMESTAMPTZ>` | `ARRAY<TIMESTAMPTZ>` | `ARRAY<TIMESTAMP>` | `VARIANT` | Coming soon! |
<br></br>

### Design Choices
We recognise that there are various approaches to handling certain data types. Here are some decisions we've taken for PeerDB.

#### Numeric Type
For Snowflake, we map PostgreSQL's `numeric` type as follows:
- `numeric` with no specified precision and scale is mapped to `NUMBER(38,20)`.
- `numeric` with precision OR scale which is beyond 38 and 37 is mapped to `NUMBER(38, 20)`.
- `numeric` with precision AND scale within the above limits is mapped to `NUMBER(precision, scale)`.

For BigQuery, we map PostgreSQL's `numeric` type as follows:
- `numeric` with no specified precision and scale is mapped to `BIGNUMERIC(38,20)`.
- `numeric` with precision OR scale which is beyond 38 and 37 respectively, is mapped to `BIGNUMERIC(38, 20)`.
- `numeric` with precision AND scale within the above limits is mapped to `BIGNUMERIC(precision, scale)`.

For Clickhouse, we map PostgreSQL's `numeric` type as follows:
- `numeric` with no specified precision and scale is mapped to `Decimal(76,38)`.
- `numeric` with precision OR scale which is beyond 76 and 38 respectively, is mapped to `Decimal(76,38)`.
- `numeric` with precision AND scale within the above limits is mapped to `Decimal(precision, scale)`.

#### Geospatial Data
PeerDB detects invalid shapes (for example, a `linestring` with only one point) among PostGIS values it pulls, and writes them as null on the destination.
We keep a log of this data and it can be retrieved if needed.

Valid geospatial data is written on BigQuery and Snowflake in `Well-Known Text (WKT)` format,
while to PostgreSQL destinations it is written as it is received.

#### HStore Data
PeerDB writes `HSTORE` data as `JSON` on BigQuery. All intricaces of the `HSTORE` data type are preserved, such as:
- `NULL` values. Example: `'"a"=>NULL'` will be written as `{"a":null}`
- Empty keys. Example: `'""=>1'` will be written as `{"":1}`
- Overriding duplicate key values. Example: `'"a"=>"1", "a"=>"2"'` will be written as `{"a":2}`

To Snowflake, it is written as a `VARIANT` data type, although it is
formatted as a `JSON` and can be queried as such - `snowflake_hstore_column:key`.

#### Nulls in BigQuery Arrays
PeerDB removes `null` values from BigQuery arrays. This is because BigQuery does not support `null` values in arrays during their insertion.
